\documentclass[tikz, letterpaper,12pt]{article}

\usepackage{geometry}
\usepackage{pslatex}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{color}
\usepackage{subcaption}
\usepackage{float}
\usepackage{tikz}
\usepackage{setspace}
\geometry{ margin = 0.93in }

\usetikzlibrary{matrix,backgrounds}
\usepackage{listings}
\usepackage{color}

\usepackage[fleqn]{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Java,
  aboveskip=3mm,
  belowskip=1mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\usepackage{amssymb, amsthm, bm, nicefrac}

\newcommand{\xto}[1]{\xrightarrow{#1}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\norm}[1]{\left\|#1\right\|}
\newcommand{\normal}{\trianglelefteq}
\renewcommand{\qedsymbol}{\rule{0.7em}{0.7em}}

\newcommand{\aaa}[1]{\hspace{0.65cm}\parbox[t]{15.3cm}{#1}}
\newcommand{\aab}[1]{\hspace{1.15cm}\parbox[t]{15.0cm}{#1}}
\newcommand{\aac}[1]{\hspace{1.65cm}\parbox[t]{15.0cm}{#1}}
\newcommand{\aad}[1]{\hspace{2.15cm}\parbox[t]{15.0cm}{#1}}
\newcommand{\aae}[1]{\hspace{2.65cm}\parbox[t]{15.0cm}{#1}}
\newcommand{\aaf}[1]{\hspace{3.15cm}\parbox[t]{15.0cm}{#1}}
\newcommand{\aag}[1]{\hspace{3.65cm}\parbox[t]{15.0cm}{#1}}
\newcommand{\aaA}[2]{\hspace{0.5cm} {\tikz[overlay] \draw (0.1, -0.1) -- (0.1, #1 * -1.5em + 0.6em);} \parbox[t]{15.0cm}{#2}}
\newcommand{\aaB}[2]{\hspace{1.0cm} {\tikz[overlay] \draw (0.1, -0.1) -- (0.1, #1 * -1.5em + 0.6em);} \parbox[t]{15.0cm}{#2}}
\newcommand{\aaC}[2]{\hspace{1.5cm} {\tikz[overlay] \draw (0.1, -0.1) -- (0.1, #1 * -1.5em + 0.6em);} \parbox[t]{15.0cm}{#2}}
\newcommand{\aaD}[2]{\hspace{2.0cm} {\tikz[overlay] \draw (0.1, -0.1) -- (0.1, #1 * -1.5em + 0.6em);} \parbox[t]{15.0cm}{#2}}
\newcommand{\aaE}[2]{\hspace{2.5cm} {\tikz[overlay] \draw (0.1, -0.1) -- (0.1, #1 * -1.5em + 0.6em);} \parbox[t]{15.0cm}{#2}}
\newcommand{\aaF}[2]{\hspace{3.0cm} {\tikz[overlay] \draw (0.1, -0.1) -- (0.1, #1 * -1.5em + 0.6em);} \parbox[t]{15.0cm}{#2}}
\newcommand{\aaG}[2]{\hspace{3.5cm} {\tikz[overlay] \draw (0.1, -0.1) -- (0.1, #1 * -1.5em + 0.6em);} \parbox[t]{15.0cm}{#2}}
\newcommand{\xxx}{\par\vspace{0.1cm}}

%%% TODO modify these variables %%%
\def\homeworknum{4}
\def\namex{Param Somane}
\def\accessx{pss5256}
%%%%

\pagestyle{fancy}
\lhead{{\bf CMPSC 465 Fall 2020}}
\chead{{\bf Writing Assignment~\homeworknum}}
\rhead{{\bf November 1, 2020}}

\newcounter{problemid}\stepcounter{problemid}
\def\newproblem{\vspace*{0.005cm}{\bf Problem~\arabic{problemid}\stepcounter{problemid}}\hfill\fbox{\parbox{0.16\textwidth}{\bf Points:}}\par}

\setlength\parindent{0em}
\setlength\parskip{8pt}
\setlength{\fboxsep}{6pt}
\newtheorem{definition}{Definition}
\newtheorem{property}{Property}
\newtheorem{claim}{Claim}
\newtheorem{fact}{Fact}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}

\makeatletter
\newenvironment{proof*}[1][\proofname]{\par
  \pushQED{\qed}%
  \normalfont \partopsep=\z@skip \topsep=\z@skip
  \trivlist
  \item[\hskip\labelsep
        \itshape
    #1\@addpunct{.}]\ignorespaces
}{%
  \popQED\endtrivlist\@endpefalse
}
\makeatother

\begin{document}

\framebox[\textwidth]{
	\parbox{0.96\textwidth}{
		\parbox{0.08\textwidth}{\bf Name:}\parbox{0.65\textwidth}{\namex}\parbox{0.12\textwidth}{\bf Access ID:}\parbox{0.14\textwidth}{\accessx}
	}
}

%% your solutions %%%
\newproblem
Let $A[1\cdots n]$ be the given array and $k$ be such that $1\leq k\leq n$. The longest subsequence of A that includes $A[k]$ is the concatenation of $opt(k)$ (which is the longest subsequence of $A[1\cdots k]$ with $A[k]$ being the last element using the definition from notes of lecture 25) with either the longest increasing subsequence of $A[k+1\cdots n]$ if $k<n$ or $\phi$ (empty array) if $k=n$. This holds because a subsequence of $A$ containing $A[k]$, given by $(A[i_1],\,A[i_2],\,\cdots,A[i_{k-1}],\,A[i_k],\,A[i_{k+1}],\,\cdots,A[i_m])$ with $i_k=k$ and $1\leq i_1< i_2< \cdots< i_k< \cdots< i_m\leq n$ is the longest (among all such subsequences) if and only if $(A[i_1],\,A[i_2],\,\cdots,A[i_{k-1}],\,A[i_k])=opt(k)$ and $(A[i_{k+1}],\,\cdots,A[i_m])$ is the longest increasing subsequence of $A[k+1\cdots n]$. Recall that the longest-increasing-subsequence algorithm (from note 25) runs in $O(n^2)$ time. Thus, we have the following algorithm. 

\begin{minipage}{0.8\textwidth}
	\aaA {22}{Algorithm Longest-Increasing-Subsequence-Ak~($A[1\cdots n],\,k\;(1\leq k\leq n)$)}\xxx
	\aab {longest-increasing-sequence$(A[1\cdots k])$; //Yields tracking-back pointers $T(i),\,\forall\,1\leq i\leq k$}\xxx
	\aab {init $index=k$;}\xxx
	\aab {init $subsequence1=\phi$;}\xxx
	\aab {init $subsequence2=\phi$;}\xxx
	\aab {init $subsequence1.append(A[k])$;}\xxx
	\aaB {3}{while $T(index)\neq 0$}\xxx
	\aac {$subsequence1.append(A[T(index)])$;}\xxx
	\aac {$index=T(index)$;}\xxx
	\aab {end while;}\xxx
	\aab {reverse $subsequence1$ //Now $subsequence1=(A[i_1],\,A[i_2],\,\cdots,\,A[i_k])=opt(k)$}\xxx
	\aab {longest-increasing-sequence$(A[k+1\cdots n])$;}\xxx
	\aab {/* The function call above yields tracking-back pointers $T'(i),$ and the length $L'(i)$ of $opt(i),\;\forall\,k+1\leq i\leq n$ */}\xxx
	\aab {Find $L'(q)=\max_{k+1\leq j\leq n}L'(j)$; //length of longest increasing subsequence of $A[k+1\cdots n]$}\xxx
	\aab {init $index=q$;}\xxx
	\aaB {3}{while $T'(index)\neq 0$}\xxx
	\aac {$subsequence2.append(A[T'(index)])$;}\xxx
	\aac {$index=T'(index)$;}\xxx
	\aab {end while;}\xxx
	\aab {reverse $subsequence2$ //Now $subsequence2=(A[i_{k+1}],\,A[i_{k+2}],\,\cdots,\,A[i_m])$}\xxx
	\aab {report $subsequence1$.concatenate$(subsequence2)$;}\xxx
	\aab {/*$(A[i_1],\,A[i_2],\,\cdots,A[i_{k-1}],\,A[k],\,A[i_{k+1}],\,\cdots,A[i_m])$*/}\xxx
	\aaa {end algorithm;}\xxx
\end{minipage}
\newpage
\textbf{Running time:} Since the algorithm longest-increasing-sequence runs in $O(m^2)$ time for an inputted array $B[1\cdots m]$, construction of the first and second subsequences above takes $O(k^2)$ and $O\left((n-k)^2\right)$ time respectively. Reversing of the sequences and their subsequent concatenation is carried out in linear time. Ergo, the algorithm runs in $O(k^2+(n-k)^2+n)=O(n^2)$ time.

\newproblem
\textbf{(Incorrect algorithm)}
Let $d(A,B)$ represent the edit-distance between the two given strings $A$ and $B$ along the same lines as defined in lecture notes 26. Observe that the largest common subsequence between $A$ and $B$ is precisely the subsequence generated by all the $a_i's$ and $b_j's$ that 'match-up' in the optimal alignment of $A$ and $B$ corresponding to the edit-distance. This is because $d(A,B)$ corresponds to the minimization of characters in $A$ and $B$ that either do not match-up due to substitution operation or are omitted by virtue of insertion or deletion. Hence, we modify the edit-distance algorithm in note 26 to construct a table $P(i,j)$ of traceback pointers along with the dynamic programming table $F(i,j)$ that is constructed by the algorithm. This will allow us to find the longest common subsequence (LCS) explicitly. The following pseudo-code, which is a modified version of the edit-distance algorithm provided in the notes, illustrates this idea.

\begin{minipage}{0.8\textwidth}
	\aaA {22}{Algorithm Lowest-Common-Sequence~($A[1\cdots n]=a_1a_2\cdots a_n,\;B[1\cdots m]=b_1b_2\cdots b_m$)}\xxx
	\aab {init $F(i,0)=i$, for any $0\leq i\leq n$;}\xxx
	\aab {init $P(i,j)=\phi$ (NULL), for any $0\leq i\leq n$, $0\leq j\leq m$;}\xxx
	\aaB {7}{for $i=1\to n$}\xxx
	\aaC {5}{for $j=1\to m$}\xxx
	\aad {$F(i,j)=\min\{F(i-1,j-1)+\delta(X[i]\neq Y[j]),\,F(i-1,j)+1,\,F(i,j-1)+1\}$;}\xxx
	\aad {if $F(i,j)=F(i-1,j-1)+\delta(X[i]\neq Y[j]):$ $P(i,j)=(i-1,j-1)$  ;}\xxx
	\aad {else if $F(i,j)=F(i-1,j)+1:$ $P(i,j)=(i-1,j)$;}\xxx
	\aad {else: $P(i,j)=(i,j-1)$;}\xxx
	\aac {end for;}\xxx
	\aab {end for;}\xxx
	\aab {init $index=(n,m)$; //Corresponds to $F(n,m)=d(A,B)$}\xxx
	\aab {/*We denote $index=(index[0],index[1])$*/}\xxx
	\aab {init $LCS=\phi$;}\xxx
	\aaB {5}{while $index\neq NULL$}\xxx
	\aaC {3}{if $A[index[0]]=B[index[1]]$}\xxx
	\aad {$LCS.append(index)$;}\xxx
	\aad {$index=P(i,j)$;}\xxx
	\aac {end if;}\xxx
	\aab {end while;}\xxx
	\aab {reverse $LCS$; //Now $LCS=\left((i_1,j_1),\,(i_2,j_2),\,\cdots (i_k,j_k)\right)$ and $A[i_l]=B[j_l]$, $\forall\,1\leq l\leq k$}\xxx
	\aab {init $k=length(LCS)$;}\xxx
	\aab {report $LCS$ and $k$;}\xxx
	\aaa {end algorithm;}\xxx
\end{minipage}
	
\textbf{Running time:} Since the table of traceback pointers $P(i,j)$ is constructed simultaneously while forming the dynamic programming table $F(i,j)$ which stores the edit distance between $A[1\cdots i]$ and $B[1\cdots j]$, running time of the algorithm is the same as the edit-distance algorithm, that is $O(|A||B|)=O(mn)$.

\newproblem
It is assumed that the points for each problem $x_i$ is non-negative. Our first goal is to divide the given problem into sub-problems such that the optimal substructure property is preserved. Define $H[1\cdots n]$ to be an array where $H[i]$ denotes the highest number of points that can be attained in the subspace $(i,\,i+1,\,i+2,\,\cdots,n)$ of all problems following the $i^{th}$ problem, for each $1\leq i\leq n$. If we elect to solve the $i^{th}$ problem, then we get $x_i$ points, along with the most number of points that can be attained by solving problems from $(i+p_i+1)^{th}$ problem onward. If we choose not to solve the $i^{th}$ problem, then the most number of points that can be attained in the above subspace will be $H[i+1]$. The optimal ordering of the problems can then be obtained by iterating through $H$. Ergo, we have the following recurrence relation:
\begin{equation*}
H[i]= \max\left\{
\begin{array}{ll}
      x_i+H[i+p_i+1]\\
      H[i+1] \\
\end{array} 
\right.
\end{equation*}
Note that the base case is $H[n]=x_n$ because only the $n^{th}$ problem can be solved in the subspace $(n)$; thus, we analyze the sub-problems in reverse order. We keep track of the problems supposed to be solved corresponding to each $H[i]$ using an array of binary lists $B[1\cdots n]$ (each $B[i]$ is an $i$-bit binary list; 0 denotes the problem with that index is supposed to be skipped while 1 denotes that the problem should be attempted). We seek $B[1]$ for which the search subspace consists of all the problems $(1,\,2,\cdots,\,n)$. This idea is portrayed in the algorithm below. 

\begin{minipage}{0.8\textwidth}
	\aaA {15.7}{Algorithm Highest-Total-Points~($p_i,\,x_i\;(\forall\,1\leq i\leq n)$)}\xxx
	\aab {init $H[1\cdots n+1]=[0]\ast n$ and $B[1\cdots n+1]=NULL\ast n$;}\xxx
	\aab {$H[n]=x_n$ and $B[n]=(1)$;}\xxx
	\aab {Set $p_i=\min\{p_i,\,n-i\}$, $\forall\,1\leq i\leq n$; //To ensure that the array index is not out of bounds}\xxx
	\aaB {10}{for $i=n-1\to 1$}\xxx
	\aac {$H[i]=\max(x_i+H[i+p_i+1],\,H[i+1])$;}\xxx
	\aaC {4}{if $H[i]=x_i+H[i+p_i+1]$ //This case is prioritized; if $p_i=0$, we still attempt problem $i$}\xxx
	\aad {$B[i].append(1)$; //We attempt problem $i$}\xxx
	\aad {$B[i].concatenate([0]\ast p_i)$; //We don't attempt the following $p_i$ problems}\xxx
	\aad {$B[i].concatenate(B[i+p_i+1])$;}\xxx
	\aaC {3}{else //$H[i]=H[i+1]$}\xxx
	\aad {$B[i].append(0)$; //We don't attempt problem $i$}\xxx
	\aad {$B[i].concatenate(B[i+1])$;}\xxx
	\aac {end if;}\xxx
	\aab {end for;}\xxx
	\aab {report $B[1]$;}\xxx
	\aaa {end algorithm;}\xxx
\end{minipage}

Note that we define $H[n+1]$ and $B[n+1]$ to account for the boundary case when $H[n+1]$ is checked in the recursion because the $n^{th}$ problem was skipped.

\textbf{Running time:} Since $H[i]$ and $B[i]$ are computed in constant time (assuming that concatenation and appending takes constant time for $B[i]$) for each $i$ within the for loop, the algorithm clearly runs in $O(n)$ time.

\newproblem
We iterate through the given array of values $V[1\cdots n]=(v_1,v_2,\cdots,v_n)$ (Kim's preferences of the ingredients) with the goal of finding the sub-array $(v_i,v_{i+1},\cdots,v_j)$ of this array that corresponds to the maximum sum $\sum_{k=i}^j v_k$ among all the continuous sub-arrays of $V$. To this end, we define two variables: $currentsum$ to store the sum of values in the current sub-array being examined and $maxsum$ to store the maximum sum among all the continuous sub-arrays
examined until the $i^{th}$ iteration $(1\leq i\leq n)$.

When $currentsum>0$, it may possibly lead to an update of $maxsum$; thus, we proceed to the next iteration while continuing to examine the current sub-array. However, $currentsum \leq 0$ implies that this sub-array either will not lead to a subsequent update of $maxsum$ or $maxsum\leq 0$ because all the $v_i\,$'s turned out to be non-positive real numbers (in this latter case, the burger will contain a single, least disliked, ingredient). Therefore, if $currentsum\leq 0$, then we can reset it to zero and begin examining a new sub-array starting from the next index. Lastly, observe that at each iteration, we set $maxsum=\max\{maxsum,\,currentsum\}$. The following algorithm illustrates this idea. 

\begin{minipage}{0.8\textwidth}
	\aaA {9}{Algorithm Most-Liked-Sum~($v_i,\;(\forall\,1\leq i\leq n)$)}\xxx
	\aab {init $currentsum=0$;}\xxx
	\aab {init $maxsum=-\infty$;}\xxx
	\aaB {4}{for $i=1\to n$}\xxx
	\aac {$currentsum=currentsum+v_i$;}\xxx
	\aac {if $maxsum<currentsum:$ $maxsum=currentsum$;}\xxx
	\aac {if $currentsum< 0:$ $currentsum=0$;}\xxx
	\aab {end for;}\xxx
	\aab {report $maxsum$;}\xxx
	\aaa {end algorithm;}\xxx
\end{minipage}

\textbf{Running time:} Since the algorithm comprises of a single for loop, in which all the computations are done in constant time, the algorithm runs in $O(n)$ time.

\newproblem
Let $a_1a_2\cdots a_i$ be an $i$-bit binary sequence (i.e. for each $1\leq j\leq i,\,a_j\in\{0,1\}$), for each $1\leq i\leq n$. Let $N[i]$ represent the number of $i$-bit sequences that contain no adjacent "1"s, for every $i$. Observe that for $i\geq 3$, if $a_i=1$, then $a_{i-1}=0$ and this implies that we have a total of $N[i-2]$ possible $(i-2)$-bit sequences that, when concatenated with "01", yield $i$-bit sequences that necessarily end in "01". On the other hand, if $a_i=0$, then all of $a_1,a_2,\cdots,a_{i-1}$ are free over $\ZZ_2=\{0,1\}$ and so we get $N[i-1]$ possible $(i-1)$-bit sequences that, when concatenated with "0", yield $i$-bit sequences that end in "0". These are the only possibilities since a sequence cannot end in "11". Moreover, for $i\leq 2$, we have the base cases $N[1]=2$ (since "0" and "1") are the only choices) and $N[2]=3$ (since "00", "01", and "10" are the only choices). As a result, we have the following recurrence relation:
\begin{align*}
N[i]= \left\{
\begin{array}{ll}
      2&,\text{if}\;\; i=1\\
      3&,\text{if}\;\; i=2\\
      N[i-1]+N[i-2]&,\text{if}\;\; i\geq 3\\
\end{array} 
\right.
\end{align*}
 We seek the value of $N[n]$, namely the number of $n$-bit sequences that contain no adjacent "1"s. Hence, we have the following pseudo-code.

\textbf{Running time:} Since the algorithm below comprises of a single for loop, and computations within it
take place in constant time, the algorithm runs in $O(n)$ time.

\begin{minipage}{0.8\textwidth}
	\aaA {9.6}{Algorithm Chanting-Patterns~($n\in\NN$)}\xxx
	\aab {init $N=\phi$; //$|N|=n$}\xxx
	\aab {if $n=1:$ report 2;}\xxx
	\aab {if $n=2:$ report 3;}\xxx
	\aab {$N[1]=2$;}\xxx
	\aab {$N[2]=3$;}\xxx
	\aaB {1.9}{for $i=3\to n$}\xxx
	\aac {$N[i]=N[i-1]+N[i-2]$;}\xxx
	\aab {end for;}\xxx
	\aab {report $N[n]$;}\xxx
	\aaa {end algorithm;}\xxx
\end{minipage}

\textbf{Bonus Problem} 

The most intuitive way to approach this problem is to cut the plank in a manner such that the plank is divided into almost equal halves at every cut. This will yield a total cost of a little over $k+\frac{k}{2}+\frac{k}{4}+\cdots$, which is clearly a lower bound for all the possible costs. However, this procedure is erroneous, as is evident by the following counterexample. Let $k=10$ and let the array of positions of markers be $M=\{1,2,3,4,5,6\}$. By the above discussion, it behooves us to make the first cut at 5. However, observe that cutting at 5 splits the plank into the left and right halves, wherein the left half can be cut with a total cost of 5(cut at 3)+2(cut at 4)+3(cut at 2)+2(cut at 1)=\$12 and \$5 for the right part. Hence, it would take $10+12+5=\$27$ to cut the entire plank. On the other hand, if we make our first cut  at 6, then the right half doesn't cost anything and the left half costs 6(cut at 5)+3(cut at 3)+2(cut at 4)+3(cut at 2)+2(cut at 1)=\$16, thereby accumulating to a cost of $10+16=\$26$ for cutting the entire plank, which is better than the \$27 obtained in the prior scenario. Thus, we now seek to develop a dynamic programming algorithm that can accomplish our goal. Let $M[1\cdots n]$ be the sorted array of positive numbers indicating the position of markers. Define $F(a,b)$ to be the minimum cost of cutting the portion of the plank between $a$ and $b$, where $a,b\in M\cup\{0,k\}$. Clearly, $F(0,k)$ is the required quantity, where $k$ is the length of the entire wooden plank and we consider both '$0$' and '$k$' as endpoint extensions of $M$. Clearly, we have $F(0,k)=\min_{m\in M}\{F(0,m)+F(m,k)\}+k$, where $\min_{m\in M}\{F(0,m)+F(m,k)\}$ represents the minimum cost of cutting the left and right portions of the plank resulting from the first cut. Generalizing this formula for any endpoints $m_1,\,m_2\in M\cup\{0,k\}$ of the region $[m_1,m_2]$ (where $m_1<m_2$) on the plank that we are examining, we provide the recursive formula
\begin{equation*}
    F(m_1,m_2)=\min_{m\in M;\;m_1<m<m_2}\{F(m_1,m)+F(m,m_2)\}+(m_2-m_1)
\end{equation*}
We first initialize $F(i,j)=\infty$ for all $i,j\in M\cup\{0,k\}$ and compute $\min_{m\in M;\;m_1<m<m_2}\{F(m_1,m)+F(m,m_2)\}$ by iterating through all $m\in M$ between $m_1$ and $m_2$ via a for loop. Note that we first need to check if $F(i,j)=\infty$ (that is, it has not been updated) and only then compute its value. Moreover, this follows from the invariant at play here that $F(i,j)$ does not change after its value has been set. Lastly, we report $F(0,k)$ at the end as the minimum cost required to make all marked cuts.

\textbf{Running time:} Since the computing part of $F(m_1,m_2)$ takes constant time because it only references values from the dynamic programming table maintained for $F$, the running time is clearly $O\left((n+2)^2\right)=O(n^2)$ as we need to fill $(n+2)^2$ values in the table for $F$.
\end{document}
